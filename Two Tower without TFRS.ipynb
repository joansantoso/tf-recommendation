{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Tower Model Recommenders System without TFRS Implementation\n",
    "By TFUG Surabaya Team (Joan Santoso, Billy K., Patrick S.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA00wBE2Ntdm"
   },
   "source": [
    "### Import Library\n",
    "Import semua library yang diperlukan. Pada tutorial ini library yang diperlukan adalah tensorflow, numpy, dan tensorflow dataset. <br>\n",
    "tensorflow digunakan sebagai framework deep learning <br>\n",
    "numpy merupakan library komputasi matematika di python <br>\n",
    "tensorflow dataset(tfds) digunakan untuk load dataset yang akan dipakai yaitu MovieLens 100K dataset.\n",
    "Dataset dapat di download di https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yzAaM85Z12D"
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [],
   "source": [
    "# Import semua library yang diperlukan.\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCxQ1CZcO2wh"
   },
   "source": [
    "### Ambil seluruh data\n",
    "Kita mengambil seluruh data dengan mengunakan tensorflow dataset, dan juga melakukan preprocessing. Preprocessing yang dilakukan adalah hanya mengambil fitur dasar pada dataset yaitu id dari user dan juga judul dari movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-mxBYjdO5m7"
   },
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "# fitur dari semua data movies\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select the basic features.\n",
    "# Hanya menggunakan judul movi dan user id(tidak menggunakan fitur lain)\n",
    "# preprocess dengan fungsi map\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"]\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W0HSfmSNCWm"
   },
   "source": [
    "Membuat dictionary untuk mengubah user id dan judul movie ke integer yang digunakan untuk layer embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9I1VTEjHzpfX"
   },
   "outputs": [],
   "source": [
    "# StringLookup digunakan untuk mengubah string ke index\n",
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "# buat vocabulary dengan StringLookup\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
    "\n",
    "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrch6rVBOB9Q"
   },
   "source": [
    "### Pembuatan Model\n",
    "\n",
    "Pada tutorial ini kita akan membuat model tanpa reccomender system sederhana tanpa menggunakan library tfrs. Hal ini dapat dilakukan dengan mengunkan framework tensorflow. Model pada bagian ini adalah model yang bersifat general. Model yang kita gunakan adalah twin-tower model dan akan menerima 3 hal yaitu model dari user, model dari movie, dan juga task yang digunakan untuk melatih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5dNbDZwOIHR"
   },
   "outputs": [],
   "source": [
    "# Kita menggunakan keras model murni(menurunkan keras model)\n",
    "class MovieLensModel(tf.keras.Model):\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      movie_model: tf.keras.Model,\n",
    "      task):\n",
    "    super().__init__()\n",
    "\n",
    "    # Memasukan user dan movie model ke model utama.\n",
    "    self.user_model = user_model\n",
    "    self.movie_model = movie_model\n",
    "\n",
    "    # menyimpan metrics untuk ditunjukan saat training\n",
    "    self.my_metrics = []\n",
    "\n",
    "    # Memasukan task ke dalam model utama\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Menghitung loss function yang telah didefinisikan\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    loss,score = self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    indices = tf.argsort(score)\n",
    "\n",
    "    return loss,score\n",
    "\n",
    "  def train_step(self, inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss,score = self.compute_loss(inputs, training=True)\n",
    "\n",
    "      # untuk regularisasi jika ada\n",
    "      regularization_loss = tf.reduce_sum(\n",
    "          [tf.reduce_sum(loss) for loss in self.losses]\n",
    "      )\n",
    "\n",
    "      total_loss = loss + regularization_loss\n",
    "\n",
    "    # Update parameter model\n",
    "    gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    metrics = {}\n",
    "    # Menghitung metrics evaluasi saat training\n",
    "    eval_score = tf.argsort(score,direction='DESCENDING').numpy()\n",
    "    top_ks = [1,5,10,50,100]\n",
    "    for k_now in top_ks :\n",
    "      score_now = eval_score[:,0:k_now]\n",
    "      acc_now = np.array([ (idx in score_now[idx].tolist()) for idx in range(len(score_now))])\n",
    "      metrics[\"top_\" + str(k_now) + \"_categorical_accuracy\"] = (acc_now.sum()/len(acc_now))\n",
    "\n",
    "    metrics[\"loss\"] = loss\n",
    "    metrics[\"regularization_loss\"] = regularization_loss\n",
    "    metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdwtgUCEOI8y"
   },
   "source": [
    "### Mendefinikan model yang dipakai dan juga task yang digunakan\n",
    "\n",
    "Model yang diapakai untuk reccomender system kali ini merupakan model yang sederhana. Arsitektur dari model user dan juga model item sama, yaitu dengan menggunakan Layer embedding yang megubah nilai integer menjadi vektor dengan dimensi tetap(pada kali ini 64).\n",
    "\n",
    "Task yang kita gunakan untuk melatih model didasarkan pada task Retrieval yang ada pada library tfrs. Task ini akan membuat jarak dari user dan movie yang ia suka dekat, dan dengan movie lain jauh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvtnUN6aUY4U"
   },
   "outputs": [],
   "source": [
    "# Mendefinisikan model untuk user dan juga movie\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "movie_model = tf.keras.Sequential([\n",
    "    movie_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "\n",
    "# Mendefinisikan objektif untuk training\n",
    "def task_retrieval(\n",
    "    query_embeddings : tf.Tensor,\n",
    "    candidate_embeddings: tf.Tensor) :\n",
    "\n",
    "  # score(kemiripan) dari semua user dan item\n",
    "  scores = tf.linalg.matmul(\n",
    "        query_embeddings, candidate_embeddings, transpose_b=True)\n",
    "\n",
    "  num_queries = tf.shape(scores)[0]\n",
    "  num_candidates = tf.shape(scores)[1]\n",
    "\n",
    "  # definisi label yang merupakan matirx identitas(user i menyukai item i)\n",
    "  labels = tf.eye(num_queries, num_candidates)\n",
    "\n",
    "  # mengunakan loss cross entropy untuk melatih\n",
    "  loss_function = tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "  loss = loss_function(y_true=labels, y_pred=scores)\n",
    "\n",
    "  return loss,scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMV0HpzmJGWk"
   },
   "source": [
    "\n",
    "### Melatih model dan Evaluasi.\n",
    "\n",
    "Pada blok ini kita melatih model pada MovieLens 100K, Mengevaluasi dan juga memprediksi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArLzxoHE1TTC"
   },
   "outputs": [],
   "source": [
    "# Membuat model retrieval.\n",
    "model = MovieLensModel(user_model, movie_model, task_retrieval)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5),run_eagerly=True)\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ratings.batch(4096), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2tQDhqkOKf1"
   },
   "outputs": [],
   "source": [
    "# Mengambil movie yang mempunyai kemiripan paling tinggi\n",
    "\n",
    "user_idx = np.array([\"42\"])\n",
    "user_rep = model.user_model(user_idx)\n",
    "\n",
    "all_movie_name = [all_item  for all_item in movies.batch(len(list(movies)))][0]\n",
    "movie_rep = model.movie_model(all_movie_name)\n",
    "\n",
    "score = tf.linalg.matmul(\n",
    "        user_rep, movie_rep, transpose_b=True)\n",
    "\n",
    "index_list = tf.argsort(score, axis=-1, direction='DESCENDING').numpy()\n",
    "rec_idx = index_list[0,0:3]\n",
    "\n",
    "print(\"Top 3 recommendations for user 42: \",all_movie_name.numpy()[rec_idx])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/recommenders/blob/main/docs/examples/quickstart.ipynb",
     "timestamp": 1690180335857
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
